
# Documentations 


## Any Docs that you might have. 


In this assignment, I have writen 3 different PySaprk codes for task1, task2, and task3. For each task, there are two datasets, one is large dataset and the other is the small dataset. So I Input all the 6 datasets into the Google Cloud Cluster and it output 6 output files. 
I have already schreenshoted the Spark history interface, for each job I have 2 schreenshots, and I upload all of them into the GitHub.

Following are my details of flies contains main Python files, Inpuy and Output:

Main python file: https://github.com/metcs/met-cs-777-assignment-1-cl812958191/

Inputs: large dataset: gs://metcs777/taxi-data-sorted-large.csv.bz2
        small dataset: gs://metcs777/taxi-data-sorted-small.csv.bz2
        
Outputs: gs://bumetcs777/output1/part-00000
         gs://bumetcs777/ouput2/part-00000
         gs://bumetcs777/ouput3/part-00000
         gs://bumetcs777/large_output1/part-00000
         gs://bumetcs777/large_output2/part-00000
         gs://bumetcs777/large_output3/part-00000
