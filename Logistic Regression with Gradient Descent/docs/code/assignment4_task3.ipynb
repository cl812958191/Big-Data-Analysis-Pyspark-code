{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from pyspark import SparkContext\n",
    "from operator import add\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "Dimention=20000\n",
    "smallTrainFile='SmallTrainingData.txt'\n",
    "TestFile='TestingData.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqArray (listOfIndices, numberofwords):\n",
    "    returnVal = np.zeros (Dimention)\n",
    "    for index in listOfIndices:\n",
    "        returnVal[index] = returnVal[index] + 1\n",
    "    returnVal = np.divide(returnVal, numberofwords)\n",
    "    return returnVal\n",
    "\n",
    "def get_label(x):\n",
    "    if 'AU' in x[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def get_vector_regularization(x):\n",
    "     return (np.multiply(x[0],x[1]),np.multiply(x[1],(np.e**float(x[2])/(1+np.e**float(x[2])))),\n",
    "             x[0]*x[2],np.log(np.e**float(x[2])+1))\n",
    "    \n",
    "def get_y_pred(x):\n",
    "    if x[1]>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No.= 0  Cost= 2385.856111198769\n",
      "Iteration No.= 1  Cost= 2286.2188405867983\n",
      "Iteration No.= 2  Cost= 2239.1706535905487\n",
      "Iteration No.= 3  Cost= 2191.3567268133243\n",
      "Iteration No.= 4  Cost= 2142.8383005955275\n",
      "Iteration No.= 5  Cost= 2093.682272400763\n",
      "Iteration No.= 6  Cost= 2043.961044251932\n",
      "Iteration No.= 7  Cost= 1993.7522690117019\n",
      "Iteration No.= 8  Cost= 1943.138496091151\n",
      "Iteration No.= 9  Cost= 1892.2067190948203\n",
      "Iteration No.= 10  Cost= 1841.0478294923196\n",
      "Iteration No.= 11  Cost= 1789.755982123528\n",
      "Iteration No.= 12  Cost= 1738.4278803702944\n",
      "Iteration No.= 13  Cost= 1687.1619911226956\n",
      "Iteration No.= 14  Cost= 1636.0577020766866\n",
      "Iteration No.= 15  Cost= 1585.2144362212289\n",
      "Iteration No.= 16  Cost= 1534.730740403616\n",
      "Iteration No.= 17  Cost= 1484.7033664213354\n",
      "Iteration No.= 18  Cost= 1435.2263640330932\n",
      "Iteration No.= 19  Cost= 1386.390205511365\n",
      "Iteration No.= 20  Cost= 1338.280960824359\n",
      "Iteration No.= 21  Cost= 1290.9795412388924\n",
      "Iteration No.= 22  Cost= 1244.5610271303622\n",
      "Iteration No.= 23  Cost= 1199.094093170962\n",
      "Iteration No.= 24  Cost= 1154.6405409795807\n",
      "Iteration No.= 25  Cost= 1111.254945920672\n",
      "Iteration No.= 26  Cost= 1068.9844212126197\n",
      "Iteration No.= 27  Cost= 1027.868499027062\n",
      "Iteration No.= 28  Cost= 987.9391249944025\n",
      "Iteration No.= 29  Cost= 949.220759618627\n",
      "Iteration No.= 30  Cost= 911.7305776554431\n",
      "Iteration No.= 31  Cost= 875.4787545937163\n",
      "Iteration No.= 32  Cost= 840.4688280347922\n",
      "Iteration No.= 33  Cost= 806.6981209852439\n",
      "Iteration No.= 34  Cost= 774.1582138318387\n",
      "Iteration No.= 35  Cost= 742.8354519942714\n",
      "Iteration No.= 36  Cost= 712.7114768749301\n",
      "Iteration No.= 37  Cost= 683.7637686594086\n",
      "Iteration No.= 38  Cost= 655.9661906773155\n",
      "Iteration No.= 39  Cost= 629.2895263241697\n",
      "Iteration No.= 40  Cost= 603.7020008936428\n",
      "Iteration No.= 41  Cost= 579.1697820083464\n",
      "Iteration No.= 42  Cost= 555.6574536132738\n",
      "Iteration No.= 43  Cost= 533.1284596698131\n",
      "Iteration No.= 44  Cost= 511.54551473487794\n",
      "Iteration No.= 45  Cost= 490.87097951753583\n",
      "Iteration No.= 46  Cost= 471.0672002745628\n",
      "Iteration No.= 47  Cost= 452.0968115465305\n",
      "Iteration No.= 48  Cost= 433.9230022645312\n",
      "Iteration No.= 49  Cost= 416.50974569632876\n",
      "Iteration No.= 50  Cost= 399.8219940731108\n",
      "Iteration No.= 51  Cost= 383.8258390662659\n",
      "Iteration No.= 52  Cost= 368.48863958571496\n",
      "Iteration No.= 53  Cost= 353.77911865875893\n",
      "Iteration No.= 54  Cost= 339.6674314247468\n",
      "Iteration No.= 55  Cost= 326.12520654152917\n",
      "Iteration No.= 56  Cost= 313.1255635330889\n",
      "Iteration No.= 57  Cost= 300.643108797793\n",
      "Iteration No.= 58  Cost= 288.6539131261367\n",
      "Iteration No.= 59  Cost= 277.1354736308563\n",
      "Iteration No.= 60  Cost= 266.0666629620057\n",
      "Iteration No.= 61  Cost= 255.42766856408596\n",
      "Iteration No.= 62  Cost= 245.19992453952432\n",
      "Iteration No.= 63  Cost= 235.36603842838076\n",
      "Iteration No.= 64  Cost= 225.90971491944168\n",
      "Iteration No.= 65  Cost= 216.8156781965996\n",
      "Iteration No.= 66  Cost= 208.0695943195551\n",
      "Iteration No.= 67  Cost= 199.65799475864452\n",
      "Iteration No.= 68  Cost= 191.56820196344245\n",
      "Iteration No.= 69  Cost= 183.7882576504257\n",
      "Iteration No.= 70  Cost= 176.30685434657286\n",
      "Iteration No.= 71  Cost= 169.11327061798437\n",
      "Iteration No.= 72  Cost= 162.19731033639667\n",
      "Iteration No.= 73  Cost= 155.54924628105655\n",
      "Iteration No.= 74  Cost= 149.15976832820402\n",
      "Iteration No.= 75  Cost= 143.0199364363417\n",
      "Iteration No.= 76  Cost= 137.12113858601455\n",
      "Iteration No.= 77  Cost= 131.45505377418002\n",
      "Iteration No.= 78  Cost= 126.01362009419525\n",
      "Iteration No.= 79  Cost= 120.78900785390182\n",
      "Iteration No.= 80  Cost= 115.77359759875499\n",
      "Iteration No.= 81  Cost= 110.95996281803336\n",
      "Iteration No.= 82  Cost= 106.34085702420481\n",
      "Iteration No.= 83  Cost= 101.90920481320958\n",
      "Iteration No.= 84  Cost= 97.6580964415049\n",
      "Iteration No.= 85  Cost= 93.58078539869626\n",
      "Iteration No.= 86  Cost= 89.67068841626272\n",
      "Iteration No.= 87  Cost= 85.92138733607841\n",
      "Iteration No.= 88  Cost= 82.32663226852462\n",
      "Iteration No.= 89  Cost= 78.88034549879167\n",
      "Iteration No.= 90  Cost= 75.57662564961431\n",
      "Iteration No.= 91  Cost= 72.40975167574591\n",
      "Iteration No.= 92  Cost= 69.3741863452899\n",
      "Iteration No.= 93  Cost= 66.46457895001069\n",
      "Iteration No.= 94  Cost= 63.675767075057024\n",
      "Iteration No.= 95  Cost= 61.00277734231754\n",
      "Iteration No.= 96  Cost= 58.440825115763886\n",
      "Iteration No.= 97  Cost= 55.98531321743615\n",
      "Iteration No.= 98  Cost= 53.63182974650097\n",
      "Iteration No.= 99  Cost= 51.376145119977046\n",
      "Iteration No.= 100  Cost= 49.21420846291535\n",
      "Iteration No.= 101  Cost= 47.14214347037187\n",
      "Iteration No.= 102  Cost= 45.156243847013606\n",
      "Iteration No.= 103  Cost= 43.252968407169554\n",
      "Iteration No.= 104  Cost= 41.428935893295865\n",
      "Iteration No.= 105  Cost= 39.680919548563125\n",
      "Iteration No.= 106  Cost= 38.00584146303584\n",
      "Iteration No.= 107  Cost= 36.40076670483291\n",
      "Iteration No.= 108  Cost= 34.862897248338264\n",
      "Iteration No.= 109  Cost= 33.389565720111015\n",
      "Iteration No.= 110  Cost= 31.978228997473543\n",
      "Iteration No.= 111  Cost= 30.626461711841007\n",
      "Iteration No.= 112  Cost= 29.33194972530237\n",
      "Iteration No.= 113  Cost= 28.092483661493308\n",
      "Iteration No.= 114  Cost= 26.905952577787634\n",
      "Iteration No.= 115  Cost= 25.770337863629976\n",
      "Iteration No.= 116  Cost= 24.68370743909973\n",
      "Iteration No.= 117  Cost= 23.64421030952393\n",
      "Iteration No.= 118  Cost= 22.650071508317357\n",
      "Iteration No.= 119  Cost= 21.69958743431353\n",
      "Iteration No.= 120  Cost= 20.79112156505078\n",
      "Iteration No.= 121  Cost= 19.923100507119837\n",
      "Iteration No.= 122  Cost= 19.094010331359446\n",
      "Iteration No.= 123  Cost= 18.302393135935407\n",
      "Iteration No.= 124  Cost= 17.546843784458723\n",
      "Iteration No.= 125  Cost= 16.82600677821248\n",
      "Iteration No.= 126  Cost= 16.13857323914288\n",
      "Iteration No.= 127  Cost= 15.483278000592009\n",
      "Iteration No.= 128  Cost= 14.858896822580565\n",
      "Iteration No.= 129  Cost= 14.26424376474701\n",
      "Iteration No.= 130  Cost= 13.69816876037662\n",
      "Iteration No.= 131  Cost= 13.159555437915014\n",
      "Iteration No.= 132  Cost= 12.647319231681905\n",
      "Iteration No.= 133  Cost= 12.160405812110863\n",
      "Iteration No.= 134  Cost= 11.697789849592422\n",
      "Iteration No.= 135  Cost= 11.258474107331486\n",
      "Iteration No.= 136  Cost= 10.841488840145255\n",
      "Iteration No.= 137  Cost= 10.445891460110113\n",
      "Iteration No.= 138  Cost= 10.070766418113875\n",
      "Iteration No.= 139  Cost= 9.715225243586254\n",
      "Iteration No.= 140  Cost= 9.378406683070255\n",
      "Iteration No.= 141  Cost= 9.05947688129283\n",
      "Iteration No.= 142  Cost= 8.757629554972807\n",
      "Iteration No.= 143  Cost= 8.472086118543919\n",
      "Iteration No.= 144  Cost= 8.20209573099941\n",
      "Iteration No.= 145  Cost= 7.946935243169474\n",
      "Iteration No.= 146  Cost= 7.705909034023722\n",
      "Iteration No.= 147  Cost= 7.478348732604413\n",
      "Iteration No.= 148  Cost= 7.263612828589536\n",
      "Iteration No.= 149  Cost= 7.06108617926985\n",
      "Iteration No.= 150  Cost= 6.870179423964403\n",
      "Iteration No.= 151  Cost= 6.690328318804841\n",
      "Iteration No.= 152  Cost= 6.52099300565239\n",
      "Iteration No.= 153  Cost= 6.3616572288926285\n",
      "Iteration No.= 154  Cost= 6.211827513248872\n",
      "Iteration No.= 155  Cost= 6.071032314750146\n",
      "Iteration No.= 156  Cost= 5.938821155762298\n",
      "Iteration No.= 157  Cost= 5.814763753650746\n",
      "Iteration No.= 158  Cost= 5.698449151310598\n",
      "Iteration No.= 159  Cost= 5.589484856516078\n",
      "Iteration No.= 160  Cost= 5.487495995854642\n",
      "Iteration No.= 161  Cost= 5.392124487954003\n",
      "Iteration No.= 162  Cost= 5.303028239763416\n",
      "Iteration No.= 163  Cost= 5.219880368865921\n",
      "Iteration No.= 164  Cost= 5.1423684540990475\n",
      "Iteration No.= 165  Cost= 5.070193816203815\n",
      "Iteration No.= 166  Cost= 5.003070829762217\n",
      "Iteration No.= 167  Cost= 4.940726267288788\n",
      "Iteration No.= 168  Cost= 4.88289867606534\n",
      "Iteration No.= 169  Cost= 4.829337788053971\n",
      "Iteration No.= 170  Cost= 4.779803963050883\n",
      "Iteration No.= 171  Cost= 4.734067665093741\n",
      "Iteration No.= 172  Cost= 4.691908972035067\n",
      "Iteration No.= 173  Cost= 4.653117118102585\n",
      "Iteration No.= 174  Cost= 4.617490069199459\n",
      "Iteration No.= 175  Cost= 4.584834130629852\n",
      "Iteration No.= 176  Cost= 4.554963586882176\n",
      "Iteration No.= 177  Cost= 4.527700373022684\n",
      "Iteration No.= 178  Cost= 4.502873777183924\n",
      "Iteration No.= 179  Cost= 4.480320173521344\n",
      "Iteration No.= 180  Cost= 4.459882784906959\n",
      "Iteration No.= 181  Cost= 4.441411474463086\n",
      "Iteration No.= 182  Cost= 4.424762564872886\n",
      "Iteration No.= 183  Cost= 4.409798684181873\n",
      "Iteration No.= 184  Cost= 4.396388636553998\n",
      "Iteration No.= 185  Cost= 4.3844072961561995\n",
      "Iteration No.= 186  Cost= 4.373735522017219\n",
      "Iteration No.= 187  Cost= 4.364260091347285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No.= 188  Cost= 4.355873648425545\n",
      "Iteration No.= 189  Cost= 4.348474665745513\n",
      "Iteration No.= 190  Cost= 4.341967413730185\n",
      "Iteration No.= 191  Cost= 4.336261934917713\n",
      "Iteration No.= 192  Cost= 4.331274018191985\n",
      "Iteration No.= 193  Cost= 4.326925168340848\n",
      "Iteration No.= 194  Cost= 4.323142566057281\n",
      "Iteration No.= 195  Cost= 4.319859013442315\n",
      "Iteration No.= 196  Cost= 4.317012860193676\n",
      "Iteration No.= 197  Cost= 4.314547905984096\n",
      "Iteration No.= 198  Cost= 4.312413275079654\n",
      "Iteration No.= 199  Cost= 4.310563260031745\n",
      "Iteration No.= 200  Cost= 4.308957132320092\n",
      "Iteration No.= 201  Cost= 4.307558919078871\n",
      "Iteration No.= 202  Cost= 4.306337146494823\n",
      "Iteration No.= 203  Cost= 4.305264552037253\n",
      "Iteration No.= 204  Cost= 4.304317769299839\n",
      "Iteration No.= 205  Cost= 4.303476990761055\n",
      "Iteration No.= 206  Cost= 4.302725615118364\n",
      "Iteration No.= 207  Cost= 4.302049886866845\n",
      "Iteration No.= 208  Cost= 4.30143853638536\n",
      "Iteration No.= 209  Cost= 4.300882428867716\n",
      "Iteration No.= 210  Cost= 4.300374229978907\n",
      "Iteration No.= 211  Cost= 4.299908095116731\n",
      "Iteration No.= 212  Cost= 4.299479387744741\n",
      "Iteration No.= 213  Cost= 4.299084430498595\n",
      "Iteration No.= 214  Cost= 4.298720290907902\n",
      "Iteration No.= 215  Cost= 4.298384601728306\n",
      "Iteration No.= 216  Cost= 4.298075414265393\n",
      "Iteration No.= 217  Cost= 4.297791081813694\n",
      "Iteration No.= 218  Cost= 4.2975301694948875\n",
      "Iteration No.= 219  Cost= 4.297291386400001\n",
      "Iteration No.= 220  Cost= 4.297073535949195\n",
      "Iteration No.= 221  Cost= 4.296875480695533\n",
      "Iteration No.= 222  Cost= 4.2966961183183265\n",
      "Iteration No.= 223  Cost= 4.296534366133576\n",
      "Iteration No.= 224  Cost= 4.29638915203333\n",
      "13442178\n",
      "35810670\n",
      "14683768\n",
      "f1 score: 0.9418777943368106\n",
      "confusion matrix: [[16859     3]\n",
      " [   36   316]]\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc = SparkContext(appName=\"LogisticRegressionTask3\")\n",
    "\n",
    "d_corpus = sc.textFile(smallTrainFile)\n",
    "\n",
    "numberOfDocs =d_corpus.count()\n",
    "\n",
    "d_keyAndText = d_corpus.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:][:-6]))\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "d_keyAndListOfWords = d_keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', x[1]).lower().split()))\n",
    "\n",
    "allWords = d_keyAndListOfWords.flatMap(lambda x: ((i,1) for i in x[1]))\n",
    "\n",
    "allCounts = allWords.reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "topWords = allCounts.top(Dimention, lambda x : x[1])\n",
    "\n",
    "topWordsK = sc.parallelize(range(Dimention))\n",
    "dictionary = topWordsK.map (lambda x : (topWords[x][0], x))\n",
    "\n",
    "allWordsWithDocID = d_keyAndListOfWords.flatMap(lambda x: ((j, x[0]) for j in x[1]))\n",
    "\n",
    "allDictionaryWords = dictionary.join (allWordsWithDocID)\n",
    "\n",
    "\n",
    "justDocAndPos = allDictionaryWords.map (lambda x: (x[1][1], x[1][0]))\n",
    "\n",
    "allDictionaryWordsInEachDoc = justDocAndPos.groupByKey()\n",
    "\n",
    "allDocsAsNumpyArrays = allDictionaryWordsInEachDoc.map(lambda x: (x[0], freqArray(x[1],len(x[1]))))\n",
    "zeroOrOne = allDocsAsNumpyArrays.map(lambda x: (x[0], np.clip (np.multiply (x[1], 9e9), 0, 1)))\n",
    "dfArray = zeroOrOne.reduce(lambda x1, x2: (\"\", np.add(x1[1], x2[1])))[1]\n",
    "multiplier = np.full(Dimention, numberOfDocs)\n",
    "idfArray = np.log(np.divide(np.full(Dimention, numberOfDocs), dfArray))\n",
    "\n",
    "allDocsAsNumpyArraysTFidf = allDocsAsNumpyArrays.map(lambda x: (x[0], np.multiply(x[1], idfArray)))\n",
    "\n",
    "\n",
    "test_corpus = sc.textFile(TestFile)\n",
    "\n",
    "numberOfDocs =test_corpus.count()\n",
    "\n",
    "test_keyAndText = test_corpus.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:][:-6]))\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "test_keyAndListOfWords = test_keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', x[1]).lower().split()))\n",
    "\n",
    "t_allWordsWithDocID = test_keyAndListOfWords.flatMap(lambda x: ((j, x[0]) for j in x[1]))\n",
    "\n",
    "t_allDictionaryWords = dictionary.join (t_allWordsWithDocID)\n",
    "\n",
    "t_justDocAndPos = t_allDictionaryWords.map (lambda x: (x[1][1], x[1][0]))\n",
    "\n",
    "t_allDictionaryWordsInEachDoc = t_justDocAndPos.groupByKey()\n",
    "\n",
    "\n",
    "t_allDocsAsNumpyArrays = t_allDictionaryWordsInEachDoc.map(lambda x: (x[0], freqArray(x[1],len(x[1]))))\n",
    "\n",
    "t_zeroOrOne = t_allDocsAsNumpyArrays.map(lambda x: (x[0], np.clip (np.multiply (x[1], 9e9), 0, 1)))\n",
    "t_dfArray = t_zeroOrOne.reduce(lambda x1, x2: (\"\", np.add(x1[1], x2[1])))[1]\n",
    "t_idfArray = np.log(np.divide(np.full(20000, numberOfDocs), 1+t_dfArray))\n",
    "t_allDocsAsNumpyArraysTFidf = t_allDocsAsNumpyArrays.map(lambda x: (x[0], np.multiply(x[1], t_idfArray)))\n",
    "\n",
    "# With Regularization\n",
    "R_current2 = np.random.normal(0, 0.1, Dimention)\n",
    "learningRate = 0.1\n",
    "num_iteration = 9999999\n",
    "oldCost = 0\n",
    "\n",
    "# I have tested many lambda, lambda=0.0001 can get a good result\n",
    "lamda = 0.00001\n",
    "\n",
    "allDocsAsNumpyArraysTFidf.cache()\n",
    "\n",
    "for i in range(num_iteration):\n",
    "\n",
    "    Y_X_Theta = allDocsAsNumpyArraysTFidf.map(lambda x: ((get_label(x), x[1], np.dot(x[1], R_current2))))\n",
    "    Gradient = Y_X_Theta.map(get_vector_regularization)\n",
    "    GradientSum = Gradient.reduce(lambda x, y: ((x[0] + y[0]), (x[1] + y[1]), (x[2] + y[2]), (x[3] + y[3])))\n",
    "\n",
    "    # calculate cost:\n",
    "    cost = GradientSum[3] - GradientSum[2] + lamda * (np.square(R_current2).sum())\n",
    "\n",
    "    oldp = np.sqrt(np.square(R_current2).sum())\n",
    "\n",
    "    R_current2 = R_current2 - learningRate *( (-GradientSum[0] + GradientSum[1])+2*lamda*R_current2)\n",
    "\n",
    "    p = np.sqrt(np.square(R_current2).sum())\n",
    "\n",
    "    # Stop if the cost is not descreasing\n",
    "    if abs(oldp - p) <= 0.008:\n",
    "        break\n",
    "\n",
    "    if (cost <= oldCost):\n",
    "        learningRate = learningRate * 1.05\n",
    "        oldCost = cost\n",
    "\n",
    "    if (cost > oldCost):\n",
    "        learningRate = learningRate * 0.5\n",
    "        oldCost = cost\n",
    "\n",
    "    print(\"Iteration No.=\", i, \" Cost=\", cost)\n",
    "    \n",
    "y_ypred2=t_allDocsAsNumpyArraysTFidf.map(lambda x: (x[0],1 if 'AU' in x[0] else 0,0 if np.dot(x[1], R_current2) <0 else 1)).collect()\n",
    "  \n",
    "y2=[]\n",
    "ypred2=[]\n",
    "counter=0\n",
    "for i in y_ypred2:\n",
    "    y2.append(i[1])\n",
    "    ypred2.append(i[2])\n",
    "    if i[1] == 0 and i[2]==1:\n",
    "        docIDList = t_allDocsAsNumpyArraysTFidf.filter(lambda x: x[0] == i[0]).collect()\n",
    "        print(docIDList[0][0])\n",
    "        counter+=1\n",
    "    if counter >=3:\n",
    "        break\n",
    "        \n",
    "print('f1 score:', f1_score(y2, ypred2, average='binary'))\n",
    "print('confusion matrix:', confusion_matrix(y2, ypred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
